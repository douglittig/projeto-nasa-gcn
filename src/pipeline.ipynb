{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "9a626959-61c8-4bba-84d2-2a4ecab1f7ec",
                    "showTitle": false,
                    "title": ""
                }
            },
            "source": [
                "# NASA GCN Data Pipeline\n",
                "\n",
                "Lakeflow Declarative Pipeline for ingesting NASA Gamma-ray Coordinates Network (GCN) events.\n",
                "\n",
                "**Architecture (Multiplex):**\n",
                "- **Bronze**: `gcn_raw` - All raw Kafka messages\n",
                "- **Silver**: Separate tables per topic category\n",
                "  - `gcn_classic_text` - Classic text format alerts\n",
                "  - `gcn_classic_voevent` - VoEvent XML format\n",
                "  - `gcn_classic_binary` - Binary format\n",
                "  - `gcn_notices` - JSON notices (new format)\n",
                "  - `gcn_circulars` - GCN Circulars\n",
                "  - `igwn_gwalert` - Gravitational wave alerts\n",
                "  - `gcn_heartbeat` - Test/heartbeat messages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "9198e987-5606-403d-9f6d-8f14e6a4017f",
                    "showTitle": false,
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "import dlt\n",
                "import sys\n",
                "\n",
                "# Add source path for local modules\n",
                "sys.path.append(spark.conf.get(\"bundle.sourcePath\", \".\"))\n",
                "\n",
                "from pyspark.sql.functions import col, decode, split, current_timestamp\n",
                "from nasa_gcn.config import get_kafka_options"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Bronze Layer: Raw Kafka Stream"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {
                "application/vnd.databricks.v1+cell": {
                    "cellMetadata": {},
                    "inputWidgets": {},
                    "nuid": "bronze-layer-cell",
                    "showTitle": false,
                    "title": ""
                }
            },
            "outputs": [],
            "source": [
                "@dlt.table(\n",
                "    name=\"gcn_raw\",\n",
                "    comment=\"Raw NASA GCN Kafka messages (all topics)\",\n",
                "    table_properties={\"quality\": \"bronze\"}\n",
                ")\n",
                "def gcn_raw():\n",
                "    \"\"\"Ingest raw messages from NASA GCN Kafka topics.\"\"\"\n",
                "    kafka_options = get_kafka_options()\n",
                "    \n",
                "    return (\n",
                "        spark.readStream\n",
                "        .format(\"kafka\")\n",
                "        .options(**kafka_options)\n",
                "        .load()\n",
                "        .select(\n",
                "            col(\"key\").cast(\"string\").alias(\"message_key\"),\n",
                "            col(\"value\"),\n",
                "            col(\"topic\"),\n",
                "            col(\"partition\"),\n",
                "            col(\"offset\"),\n",
                "            col(\"timestamp\").alias(\"kafka_timestamp\"),\n",
                "            current_timestamp().alias(\"ingestion_timestamp\")\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Silver Layer: Multiplex Tables by Topic Category"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dlt.table(\n",
                "    name=\"gcn_classic_text\",\n",
                "    comment=\"Classic text format GCN alerts\",\n",
                "    table_properties={\"quality\": \"silver\"}\n",
                ")\n",
                "def gcn_classic_text():\n",
                "    \"\"\"Filter and decode classic text format messages.\"\"\"\n",
                "    return (\n",
                "        dlt.read_stream(\"gcn_raw\")\n",
                "        .filter(col(\"topic\").startswith(\"gcn.classic.text.\"))\n",
                "        .select(\n",
                "            col(\"message_key\"),\n",
                "            decode(col(\"value\"), \"UTF-8\").alias(\"message_text\"),\n",
                "            col(\"topic\"),\n",
                "            split(col(\"topic\"), r\"\\.\").getItem(3).alias(\"event_type\"),\n",
                "            col(\"kafka_timestamp\"),\n",
                "            col(\"ingestion_timestamp\"),\n",
                "            col(\"partition\"),\n",
                "            col(\"offset\")\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dlt.table(\n",
                "    name=\"gcn_classic_voevent\",\n",
                "    comment=\"Classic VoEvent XML format GCN alerts\",\n",
                "    table_properties={\"quality\": \"silver\"}\n",
                ")\n",
                "def gcn_classic_voevent():\n",
                "    \"\"\"Filter and decode VoEvent XML format messages.\"\"\"\n",
                "    return (\n",
                "        dlt.read_stream(\"gcn_raw\")\n",
                "        .filter(col(\"topic\").startswith(\"gcn.classic.voevent.\"))\n",
                "        .select(\n",
                "            col(\"message_key\"),\n",
                "            decode(col(\"value\"), \"UTF-8\").alias(\"voevent_xml\"),\n",
                "            col(\"topic\"),\n",
                "            split(col(\"topic\"), r\"\\.\").getItem(3).alias(\"event_type\"),\n",
                "            col(\"kafka_timestamp\"),\n",
                "            col(\"ingestion_timestamp\"),\n",
                "            col(\"partition\"),\n",
                "            col(\"offset\")\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dlt.table(\n",
                "    name=\"gcn_classic_binary\",\n",
                "    comment=\"Classic binary format GCN alerts\",\n",
                "    table_properties={\"quality\": \"silver\"}\n",
                ")\n",
                "def gcn_classic_binary():\n",
                "    \"\"\"Filter binary format messages (keep as raw bytes).\"\"\"\n",
                "    return (\n",
                "        dlt.read_stream(\"gcn_raw\")\n",
                "        .filter(col(\"topic\").startswith(\"gcn.classic.binary.\"))\n",
                "        .select(\n",
                "            col(\"message_key\"),\n",
                "            col(\"value\").alias(\"binary_data\"),\n",
                "            col(\"topic\"),\n",
                "            split(col(\"topic\"), r\"\\.\").getItem(3).alias(\"event_type\"),\n",
                "            col(\"kafka_timestamp\"),\n",
                "            col(\"ingestion_timestamp\"),\n",
                "            col(\"partition\"),\n",
                "            col(\"offset\")\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dlt.table(\n",
                "    name=\"gcn_notices\",\n",
                "    comment=\"New JSON format GCN notices\",\n",
                "    table_properties={\"quality\": \"silver\"}\n",
                ")\n",
                "def gcn_notices():\n",
                "    \"\"\"Filter and decode JSON format notices.\"\"\"\n",
                "    return (\n",
                "        dlt.read_stream(\"gcn_raw\")\n",
                "        .filter(col(\"topic\").startswith(\"gcn.notices.\"))\n",
                "        .select(\n",
                "            col(\"message_key\"),\n",
                "            decode(col(\"value\"), \"UTF-8\").alias(\"notice_json\"),\n",
                "            col(\"topic\"),\n",
                "            # Extract mission from topic: gcn.notices.{mission}.{type}\n",
                "            split(col(\"topic\"), r\"\\.\").getItem(2).alias(\"mission\"),\n",
                "            col(\"kafka_timestamp\"),\n",
                "            col(\"ingestion_timestamp\"),\n",
                "            col(\"partition\"),\n",
                "            col(\"offset\")\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dlt.table(\n",
                "    name=\"gcn_circulars\",\n",
                "    comment=\"GCN Circulars (astronomer reports)\",\n",
                "    table_properties={\"quality\": \"silver\"}\n",
                ")\n",
                "def gcn_circulars():\n",
                "    \"\"\"Filter and decode GCN Circulars.\"\"\"\n",
                "    return (\n",
                "        dlt.read_stream(\"gcn_raw\")\n",
                "        .filter(col(\"topic\") == \"gcn.circulars\")\n",
                "        .select(\n",
                "            col(\"message_key\"),\n",
                "            decode(col(\"value\"), \"UTF-8\").alias(\"circular_json\"),\n",
                "            col(\"topic\"),\n",
                "            col(\"kafka_timestamp\"),\n",
                "            col(\"ingestion_timestamp\"),\n",
                "            col(\"partition\"),\n",
                "            col(\"offset\")\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dlt.table(\n",
                "    name=\"igwn_gwalert\",\n",
                "    comment=\"IGWN Gravitational Wave Alerts\",\n",
                "    table_properties={\"quality\": \"silver\"}\n",
                ")\n",
                "def igwn_gwalert():\n",
                "    \"\"\"Filter and decode gravitational wave alerts.\"\"\"\n",
                "    return (\n",
                "        dlt.read_stream(\"gcn_raw\")\n",
                "        .filter(col(\"topic\") == \"igwn.gwalert\")\n",
                "        .select(\n",
                "            col(\"message_key\"),\n",
                "            decode(col(\"value\"), \"UTF-8\").alias(\"gwalert_json\"),\n",
                "            col(\"topic\"),\n",
                "            col(\"kafka_timestamp\"),\n",
                "            col(\"ingestion_timestamp\"),\n",
                "            col(\"partition\"),\n",
                "            col(\"offset\")\n",
                "        )\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "@dlt.table(\n",
                "    name=\"gcn_heartbeat\",\n",
                "    comment=\"GCN Heartbeat/test messages\",\n",
                "    table_properties={\"quality\": \"silver\"}\n",
                ")\n",
                "def gcn_heartbeat():\n",
                "    \"\"\"Filter heartbeat messages (useful for monitoring).\"\"\"\n",
                "    return (\n",
                "        dlt.read_stream(\"gcn_raw\")\n",
                "        .filter(col(\"topic\") == \"gcn.heartbeat\")\n",
                "        .select(\n",
                "            col(\"message_key\"),\n",
                "            decode(col(\"value\"), \"UTF-8\").alias(\"heartbeat_json\"),\n",
                "            col(\"topic\"),\n",
                "            col(\"kafka_timestamp\"),\n",
                "            col(\"ingestion_timestamp\"),\n",
                "            col(\"partition\"),\n",
                "            col(\"offset\")\n",
                "        )\n",
                "    )"
            ]
        }
    ],
    "metadata": {
        "application/vnd.databricks.v1+notebook": {
            "dashboards": [],
            "language": "python",
            "notebookMetadata": {
                "pythonIndentUnit": 4
            },
            "notebookName": "pipeline",
            "widgets": {}
        },
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}