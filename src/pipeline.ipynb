{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ NASA GCN Data Pipeline\n",
    "\n",
    "Pipeline **Delta Live Tables (DLT)** para ingest√£o de eventos astron√¥micos da NASA GCN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import dlt\n",
    "\n",
    "# Configura paths\n",
    "bundle_source_path = spark.conf.get(\"bundle.sourcePath\", \".\")\n",
    "sys.path.append(bundle_source_path)\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    coalesce,\n",
    "    col,\n",
    "    collect_list,\n",
    "    concat_ws,\n",
    "    count,\n",
    "    current_date,\n",
    "    current_timestamp,\n",
    "    expr,\n",
    "    from_json,\n",
    "    get_json_object,\n",
    "    length,\n",
    "    lit,\n",
    "    max,\n",
    "    regexp_extract,\n",
    "    regexp_replace,\n",
    "    size,\n",
    "    split,\n",
    "    trim,\n",
    "    udf,\n",
    "    when,\n",
    ")\n",
    "\n",
    "from nasa_gcn.config import get_kafka_options\n",
    "from nasa_gcn.schemas import CIRCULAR_SCHEMA\n",
    "from nasa_gcn.utils import clean_json_id, decode_utf8\n",
    "\n",
    "# --- INLINED CODE: BINARY PARSER (Devido a erro de importa√ß√£o em workers DLT) ---\n",
    "# Nota: Inserido diretamente no notebook para garantir execu√ß√£o no PySpark Worker sem dependency hell\n",
    "\n",
    "PACKET_TYPE_NAMES = {\n",
    "    1: \"BATSE_ORIGINAL\",\n",
    "    2: \"TEST\",\n",
    "    3: \"IMALIVE\",\n",
    "    4: \"KILL\",\n",
    "    11: \"BATSE_MAXBC\",\n",
    "    21: \"BRADFORD_TEST\",\n",
    "    22: \"BATSE_FINAL\",\n",
    "    24: \"BATSE_LOCBURST\",\n",
    "    60: \"SWIFT_BAT_GRB_ALERT\",\n",
    "    61: \"SWIFT_BAT_GRB_POSITION\",\n",
    "    100: \"SUPERAGILE_GRB_WAKEUP\",\n",
    "    110: \"FERMI_GBM_ALERT\",\n",
    "    111: \"FERMI_GBM_FLT_POS\",\n",
    "    112: \"FERMI_GBM_GND_POS\",\n",
    "    115: \"FERMI_GBM_FINAL_POS\",\n",
    "    120: \"FERMI_LAT_GRB_POS_INI\",\n",
    "    121: \"FERMI_LAT_GRB_POS_UPD\",\n",
    "    150: \"LVC_PRELIMINARY\",\n",
    "    151: \"LVC_INITIAL\",\n",
    "    152: \"LVC_UPDATE\",\n",
    "    164: \"LVC_RETRACTION\",\n",
    "}\n",
    "\n",
    "TJD_EPOCH = datetime(1968, 5, 24, 0, 0, 0)\n",
    "\n",
    "\n",
    "def get_packet_type_name(pkt_type: int) -> str:\n",
    "    return PACKET_TYPE_NAMES.get(pkt_type, f\"UNKNOWN_{pkt_type}\")\n",
    "\n",
    "\n",
    "def tjd_sod_to_datetime(tjd: int, sod_centi: int):\n",
    "    if tjd <= 0 or sod_centi < 0:\n",
    "        return None\n",
    "    try:\n",
    "        return TJD_EPOCH + timedelta(days=tjd, seconds=sod_centi / 100.0)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def centi_to_deg(value: int, scale: int = 100) -> float:\n",
    "    return value / scale\n",
    "\n",
    "\n",
    "def parse_gcn_binary_packet(binary_data: bytes):\n",
    "    result = {\n",
    "        \"pkt_type\": None,\n",
    "        \"pkt_type_name\": None,\n",
    "        \"pkt_sernum\": None,\n",
    "        \"trig_num\": None,\n",
    "        \"burst_datetime\": None,\n",
    "        \"burst_ra_deg\": None,\n",
    "        \"burst_dec_deg\": None,\n",
    "        \"burst_error_deg\": None,\n",
    "        \"trigger_id\": None,\n",
    "        \"parse_error\": None,\n",
    "    }\n",
    "    if binary_data is None or len(binary_data) != 160:\n",
    "        result[\"parse_error\"] = \"Invalid packet size\"\n",
    "        return result\n",
    "    try:\n",
    "        longs = struct.unpack(\">40i\", binary_data)\n",
    "        pkt_type = longs[0]\n",
    "        result[\"pkt_type\"] = pkt_type\n",
    "        result[\"pkt_type_name\"] = get_packet_type_name(pkt_type)\n",
    "        result[\"pkt_sernum\"] = longs[1]\n",
    "\n",
    "        trig_num = longs[4]\n",
    "        result[\"trig_num\"] = trig_num if trig_num > 0 else None\n",
    "\n",
    "        burst_tjd = longs[5]\n",
    "        burst_sod = longs[6]\n",
    "        if burst_tjd > 0 and burst_sod >= 0:\n",
    "            dt = tjd_sod_to_datetime(burst_tjd, burst_sod)\n",
    "            if dt:\n",
    "                result[\"burst_datetime\"] = dt.isoformat()\n",
    "\n",
    "        burst_ra = longs[7]\n",
    "        burst_dec = longs[8]\n",
    "        burst_error = longs[11]\n",
    "\n",
    "        # Heur√≠stica de escala\n",
    "        scale = 10000 if (burst_ra > 36000 or burst_ra < 0 or abs(burst_dec) > 9000) else 100\n",
    "\n",
    "        ra_deg = centi_to_deg(burst_ra, scale)\n",
    "        dec_deg = centi_to_deg(burst_dec, scale)\n",
    "\n",
    "        if 0 <= ra_deg < 360:\n",
    "            result[\"burst_ra_deg\"] = ra_deg\n",
    "        if -90 <= dec_deg <= 90:\n",
    "            result[\"burst_dec_deg\"] = dec_deg\n",
    "        result[\"burst_error_deg\"] = centi_to_deg(abs(burst_error), scale)\n",
    "        result[\"trigger_id\"] = longs[18]\n",
    "\n",
    "    except Exception as e:\n",
    "        result[\"parse_error\"] = str(e)\n",
    "    return result\n",
    "\n",
    "\n",
    "PARSED_BINARY_SCHEMA = \"pkt_type INT, pkt_type_name STRING, pkt_sernum INT, trig_num INT, burst_tjd INT, burst_sod_centi INT, burst_datetime STRING, burst_ra_deg DOUBLE, burst_dec_deg DOUBLE, burst_error_deg DOUBLE, trigger_id INT, misc INT, parse_error STRING\"\n",
    "# --- FIM INLINED CODE ---\n",
    "\n",
    "parse_binary_udf = udf(parse_gcn_binary_packet, PARSED_BINARY_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•â Bronze Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"gcn_raw\",\n",
    "    comment=\"Raw NASA GCN Kafka messages - Bronze layer\",\n",
    "    table_properties={\"quality\": \"bronze\"},\n",
    ")\n",
    "def gcn_raw():\n",
    "    kafka_options = get_kafka_options()\n",
    "    return (\n",
    "        spark.readStream.format(\"kafka\")\n",
    "        .options(**kafka_options)\n",
    "        .load()\n",
    "        .select(\n",
    "            col(\"key\").cast(\"string\").alias(\"message_key\"),\n",
    "            col(\"value\"),\n",
    "            col(\"topic\"),\n",
    "            col(\"partition\"),\n",
    "            col(\"offset\"),\n",
    "            col(\"timestamp\").alias(\"kafka_timestamp\"),\n",
    "            current_timestamp().alias(\"ingestion_timestamp\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•à Silver Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"gcn_classic_text\",\n",
    "    comment=\"Classic text format GCN alerts optimized for RAG - Silver layer\",\n",
    "    table_properties={\"quality\": \"silver\"},\n",
    ")\n",
    "def gcn_classic_text():\n",
    "    return (\n",
    "        dlt.read_stream(\"gcn_raw\")\n",
    "        .filter(col(\"topic\").startswith(\"gcn.classic.text.\"))\n",
    "        .withColumn(\"text_decoded\", decode_utf8())\n",
    "        .select(\n",
    "            col(\"message_key\"),\n",
    "            col(\"text_decoded\").alias(\"message_text\"),\n",
    "            col(\"topic\"),\n",
    "            split(col(\"topic\"), r\"\\.\").getItem(3).alias(\"event_type\"),\n",
    "            # Extracted RAG Fields\n",
    "            regexp_extract(col(\"text_decoded\"), r\"TITLE:\\s+(.*?)(?=\\n)\", 1).alias(\"title\"),\n",
    "            regexp_extract(col(\"text_decoded\"), r\"NOTICE_DATE:\\s+(.*?)(?=\\n)\", 1).alias(\n",
    "                \"notice_date\"\n",
    "            ),\n",
    "            regexp_extract(col(\"text_decoded\"), r\"NOTICE_TYPE:\\s+(.*?)(?=\\n)\", 1).alias(\n",
    "                \"notice_type\"\n",
    "            ),\n",
    "            # Document Text for RAG\n",
    "            col(\"text_decoded\").alias(\"document_text\"),\n",
    "            col(\"kafka_timestamp\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            col(\"partition\"),\n",
    "            col(\"offset\"),\n",
    "            current_timestamp().alias(\"silver_processed_timestamp\"),\n",
    "            current_date().alias(\"silver_processed_date\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"gcn_classic_voevent\",\n",
    "    comment=\"Classic VoEvent XML format GCN alerts optimized for RAG - Silver layer\",\n",
    "    table_properties={\"quality\": \"silver\"},\n",
    ")\n",
    "def gcn_classic_voevent():\n",
    "    return (\n",
    "        dlt.read_stream(\"gcn_raw\")\n",
    "        .filter(col(\"topic\").startswith(\"gcn.classic.voevent.\"))\n",
    "        .withColumn(\"xml_str\", decode_utf8())\n",
    "        .select(\n",
    "            col(\"message_key\"),\n",
    "            col(\"xml_str\").alias(\"voevent_xml\"),\n",
    "            col(\"topic\"),\n",
    "            split(col(\"topic\"), r\"\\.\").getItem(3).alias(\"event_type\"),\n",
    "            # XPath Extractions for RAG\n",
    "            expr(\"xpath_string(xml_str, '/*[local-name()=\\\"VOEvent\\\"]/@ivorn')\").alias(\"ivorn\"),\n",
    "            expr(\"xpath_string(xml_str, '/*[local-name()=\\\"VOEvent\\\"]/@role')\").alias(\"role\"),\n",
    "            expr(\n",
    "                'xpath_string(xml_str, \\'/*[local-name()=\"VOEvent\"]/*[local-name()=\"Who\"]/*[local-name()=\"Date\"]\\')'\n",
    "            ).alias(\"date\"),\n",
    "            expr(\n",
    "                'xpath_string(xml_str, \\'/*[local-name()=\"VOEvent\"]/*[local-name()=\"Why\"]/*[local-name()=\"Inference\"]/*[local-name()=\"Concept\"]\\')'\n",
    "            ).alias(\"concept\"),\n",
    "            # Document Text for RAG\n",
    "            concat_ws(\n",
    "                \" | \",\n",
    "                concat_ws(\n",
    "                    \": \",\n",
    "                    lit(\"ID\"),\n",
    "                    expr(\"xpath_string(xml_str, '/*[local-name()=\\\"VOEvent\\\"]/@ivorn')\"),\n",
    "                ),\n",
    "                concat_ws(\n",
    "                    \": \",\n",
    "                    lit(\"ROLE\"),\n",
    "                    expr(\"xpath_string(xml_str, '/*[local-name()=\\\"VOEvent\\\"]/@role')\"),\n",
    "                ),\n",
    "                concat_ws(\n",
    "                    \": \",\n",
    "                    lit(\"DATE\"),\n",
    "                    expr(\n",
    "                        'xpath_string(xml_str, \\'/*[local-name()=\"VOEvent\"]/*[local-name()=\"Who\"]/*[local-name()=\"Date\"]\\')'\n",
    "                    ),\n",
    "                ),\n",
    "                concat_ws(\n",
    "                    \": \",\n",
    "                    lit(\"CONCEPT\"),\n",
    "                    expr(\n",
    "                        'xpath_string(xml_str, \\'/*[local-name()=\"VOEvent\"]/*[local-name()=\"Why\"]/*[local-name()=\"Inference\"]/*[local-name()=\"Concept\"]\\')'\n",
    "                    ),\n",
    "                ),\n",
    "                concat_ws(\n",
    "                    \": \",\n",
    "                    lit(\"DESCRIPTION\"),\n",
    "                    expr(\n",
    "                        'xpath_string(xml_str, \\'/*[local-name()=\"VOEvent\"]/*[local-name()=\"How\"]/*[local-name()=\"Description\"]\\')'\n",
    "                    ),\n",
    "                ),\n",
    "            ).alias(\"document_text\"),\n",
    "            col(\"kafka_timestamp\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            col(\"partition\"),\n",
    "            col(\"offset\"),\n",
    "            current_timestamp().alias(\"silver_processed_timestamp\"),\n",
    "            current_date().alias(\"silver_processed_date\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"gcn_classic_binary\",\n",
    "    comment=\"Classic binary format GCN alerts optimized for RAG - Silver layer\",\n",
    "    table_properties={\"quality\": \"silver\"},\n",
    ")\n",
    "def gcn_classic_binary():\n",
    "    return (\n",
    "        dlt.read_stream(\"gcn_raw\")\n",
    "        .filter(col(\"topic\").startswith(\"gcn.classic.binary.\"))\n",
    "        .withColumn(\"parsed\", parse_binary_udf(col(\"value\")))\n",
    "        .select(\n",
    "            col(\"message_key\"),\n",
    "            col(\"parsed.pkt_type\"),\n",
    "            col(\"parsed.pkt_type_name\"),\n",
    "            col(\"parsed.pkt_sernum\"),\n",
    "            col(\"parsed.trig_num\"),\n",
    "            col(\"parsed.burst_datetime\"),\n",
    "            col(\"parsed.burst_ra_deg\"),\n",
    "            col(\"parsed.burst_dec_deg\"),\n",
    "            col(\"parsed.burst_error_deg\"),\n",
    "            col(\"parsed.trigger_id\"),\n",
    "            col(\"parsed.parse_error\"),\n",
    "            col(\"topic\"),\n",
    "            split(col(\"topic\"), r\"\\.\").getItem(3).alias(\"event_type\"),\n",
    "            # Document Text for RAG\n",
    "            concat_ws(\n",
    "                \" | \",\n",
    "                concat_ws(\": \", lit(\"TYPE\"), col(\"parsed.pkt_type_name\")),\n",
    "                when(\n",
    "                    col(\"parsed.trig_num\").isNotNull(),\n",
    "                    concat_ws(\": \", lit(\"TRIG_NUM\"), col(\"parsed.trig_num\")),\n",
    "                ),\n",
    "                when(\n",
    "                    col(\"parsed.burst_datetime\").isNotNull(),\n",
    "                    concat_ws(\": \", lit(\"DATE\"), col(\"parsed.burst_datetime\")),\n",
    "                ),\n",
    "                when(\n",
    "                    col(\"parsed.burst_ra_deg\").isNotNull(),\n",
    "                    concat_ws(\n",
    "                        \", \",\n",
    "                        concat_ws(\": \", lit(\"RA\"), col(\"parsed.burst_ra_deg\")),\n",
    "                        concat_ws(\": \", lit(\"DEC\"), col(\"parsed.burst_dec_deg\")),\n",
    "                    ),\n",
    "                ),\n",
    "            ).alias(\"document_text\"),\n",
    "            col(\"kafka_timestamp\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            col(\"partition\"),\n",
    "            col(\"offset\"),\n",
    "            current_timestamp().alias(\"silver_processed_timestamp\"),\n",
    "            current_date().alias(\"silver_processed_date\"),\n",
    "            col(\"value\").alias(\"raw_binary\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN Notices - Otimizado para RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"gcn_notices\",\n",
    "    comment=\"New JSON format GCN notices optimized for RAG - Silver layer\",\n",
    "    table_properties={\"quality\": \"silver\"},\n",
    ")\n",
    "def gcn_notices():\n",
    "    \"\"\"GCN Notices com campos comuns extra√≠dos para RAG.\n",
    "\n",
    "    Suporta m√∫ltiplas miss√µes: IceCube, Super-Kamiokande, Einstein Probe, Fermi, Swift.\n",
    "    Trata arrays JSON e campos nulos de diferentes schemas.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        dlt.read_stream(\"gcn_raw\")\n",
    "        .filter(col(\"topic\").startswith(\"gcn.notices.\"))\n",
    "        .withColumn(\"json_str\", decode_utf8())\n",
    "        # Extrair campos raw\n",
    "        .withColumn(\"_mission\", get_json_object(col(\"json_str\"), \"$.mission\"))\n",
    "        .withColumn(\"_messenger\", get_json_object(col(\"json_str\"), \"$.messenger\"))\n",
    "        .withColumn(\"_alert_type\", get_json_object(col(\"json_str\"), \"$.alert_type\"))\n",
    "        .withColumn(\n",
    "            \"_id_raw\",\n",
    "            coalesce(\n",
    "                get_json_object(col(\"json_str\"), \"$.id\"),\n",
    "                get_json_object(col(\"json_str\"), \"$.event_name\"),\n",
    "                get_json_object(col(\"json_str\"), \"$.trigger_id\"),\n",
    "            ),\n",
    "        )\n",
    "        .select(\n",
    "            col(\"message_key\"),\n",
    "            col(\"json_str\").alias(\"notice_json\"),\n",
    "            col(\"topic\"),\n",
    "            # Miss√£o do t√≥pico\n",
    "            split(col(\"topic\"), r\"\\.\").getItem(2).alias(\"mission\"),\n",
    "            # Campos extra√≠dos com fallback para topic\n",
    "            coalesce(col(\"_mission\"), split(col(\"topic\"), r\"\\.\").getItem(2)).alias(\"mission_name\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.instrument\").alias(\"instrument\"),\n",
    "            coalesce(col(\"_messenger\"), lit(\"Unknown\")).alias(\"messenger\"),\n",
    "            # Notice ID limpo (sem colchetes de array)\n",
    "            clean_json_id(col(\"_id_raw\")).alias(\"notice_id\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.pipeline\").alias(\"pipeline\"),\n",
    "            coalesce(col(\"_alert_type\"), lit(\"notice\")).alias(\"alert_type\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.alert_tense\").alias(\"alert_tense\"),\n",
    "            # Timestamps\n",
    "            get_json_object(col(\"json_str\"), \"$.trigger_time\").alias(\"trigger_time\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.alert_datetime\").alias(\"alert_datetime\"),\n",
    "            # Coordenadas\n",
    "            get_json_object(col(\"json_str\"), \"$.ra\").cast(\"double\").alias(\"ra\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.dec\").cast(\"double\").alias(\"dec\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.ra_dec_error\").alias(\"ra_dec_error\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.containment_probability\").alias(\n",
    "                \"containment_probability\"\n",
    "            ),\n",
    "            # Campos espec√≠ficos de neutrinos\n",
    "            get_json_object(col(\"json_str\"), \"$.n_events\").alias(\"n_events\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.nu_energy\").alias(\"nu_energy\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.p_astro\").alias(\"p_astro\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.luminosity_distance\").alias(\"luminosity_distance\"),\n",
    "            # Metadados\n",
    "            length(col(\"json_str\")).alias(\"json_length\"),\n",
    "            # Document text para RAG (s√≥ inclui campos n√£o-nulos)\n",
    "            concat_ws(\n",
    "                \" | \",\n",
    "                when(col(\"_mission\").isNotNull(), concat_ws(\": \", lit(\"MISSION\"), col(\"_mission\"))),\n",
    "                when(\n",
    "                    col(\"_messenger\").isNotNull(),\n",
    "                    concat_ws(\": \", lit(\"MESSENGER\"), col(\"_messenger\")),\n",
    "                ),\n",
    "                when(\n",
    "                    col(\"_alert_type\").isNotNull(), concat_ws(\": \", lit(\"TYPE\"), col(\"_alert_type\"))\n",
    "                ),\n",
    "                when(\n",
    "                    col(\"_id_raw\").isNotNull(),\n",
    "                    concat_ws(\": \", lit(\"ID\"), clean_json_id(col(\"_id_raw\"))),\n",
    "                ),\n",
    "                when(\n",
    "                    get_json_object(col(\"json_str\"), \"$.ra\").isNotNull(),\n",
    "                    concat_ws(\": \", lit(\"RA\"), get_json_object(col(\"json_str\"), \"$.ra\")),\n",
    "                ),\n",
    "                when(\n",
    "                    get_json_object(col(\"json_str\"), \"$.dec\").isNotNull(),\n",
    "                    concat_ws(\": \", lit(\"DEC\"), get_json_object(col(\"json_str\"), \"$.dec\")),\n",
    "                ),\n",
    "            ).alias(\"document_text\"),\n",
    "            col(\"kafka_timestamp\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            col(\"partition\"),\n",
    "            col(\"offset\"),\n",
    "            current_timestamp().alias(\"silver_processed_timestamp\"),\n",
    "            current_date().alias(\"silver_processed_date\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN Circulars - Otimizado para RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"gcn_circulars\",\n",
    "    comment=\"GCN Circulars - astronomer reports optimized for RAG - Silver layer\",\n",
    "    table_properties={\"quality\": \"silver\"},\n",
    ")\n",
    "def gcn_circulars():\n",
    "    return (\n",
    "        dlt.read_stream(\"gcn_raw\")\n",
    "        .filter(col(\"topic\") == \"gcn.circulars\")\n",
    "        .withColumn(\"json_str\", decode_utf8())\n",
    "        .withColumn(\"parsed\", from_json(col(\"json_str\"), CIRCULAR_SCHEMA))\n",
    "        .select(\n",
    "            col(\"message_key\"),\n",
    "            col(\"json_str\").alias(\"circular_json\"),\n",
    "            col(\"parsed.circularId\").alias(\"circular_id\"),\n",
    "            col(\"parsed.eventId\").alias(\"event_id\"),\n",
    "            col(\"parsed.subject\").alias(\"subject\"),\n",
    "            col(\"parsed.body\").alias(\"body\"),\n",
    "            col(\"parsed.submitter\").alias(\"submitter\"),\n",
    "            trim(regexp_extract(col(\"parsed.submitter\"), r\"^([^<]+)\", 1)).alias(\"submitter_name\"),\n",
    "            regexp_extract(col(\"parsed.submitter\"), r\"<([^>]+)>\", 1).alias(\"submitter_email\"),\n",
    "            col(\"parsed.submittedHow\").alias(\"submitted_how\"),\n",
    "            (col(\"parsed.createdOn\") / 1000).cast(\"timestamp\").alias(\"created_on\"),\n",
    "            regexp_extract(col(\"parsed.eventId\"), r\"^([A-Z]+)\", 1).alias(\"event_type\"),\n",
    "            size(split(trim(col(\"parsed.body\")), \" \")).alias(\"word_count\"),\n",
    "            length(col(\"parsed.body\")).alias(\"char_count\"),\n",
    "            concat_ws(\n",
    "                \"\\n\",\n",
    "                concat_ws(\": \", lit(\"SUBJECT\"), col(\"parsed.subject\")),\n",
    "                concat_ws(\": \", lit(\"EVENT\"), col(\"parsed.eventId\")),\n",
    "                concat_ws(\n",
    "                    \": \",\n",
    "                    lit(\"AUTHOR\"),\n",
    "                    trim(regexp_extract(col(\"parsed.submitter\"), r\"^([^<]+)\", 1)),\n",
    "                ),\n",
    "                lit(\"---\"),\n",
    "                col(\"parsed.body\"),\n",
    "            ).alias(\"document_text\"),\n",
    "            col(\"topic\"),\n",
    "            col(\"kafka_timestamp\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            col(\"partition\"),\n",
    "            col(\"offset\"),\n",
    "            current_timestamp().alias(\"silver_processed_timestamp\"),\n",
    "            current_date().alias(\"silver_processed_date\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"igwn_gwalert\",\n",
    "    comment=\"IGWN Gravitational Wave Alerts optimized for RAG - Silver layer\",\n",
    "    table_properties={\"quality\": \"silver\"},\n",
    ")\n",
    "def igwn_gwalert():\n",
    "    return (\n",
    "        dlt.read_stream(\"gcn_raw\")\n",
    "        .filter(col(\"topic\") == \"igwn.gwalert\")\n",
    "        .withColumn(\"json_str\", decode_utf8())\n",
    "        .withColumn(\"superevent_id\", get_json_object(col(\"json_str\"), \"$.superevent_id\"))\n",
    "        .withColumn(\"alert_type\", get_json_object(col(\"json_str\"), \"$.alert_type\"))\n",
    "        .withColumn(\"group\", get_json_object(col(\"json_str\"), \"$.event.group\"))\n",
    "        .withColumn(\"pipeline\", get_json_object(col(\"json_str\"), \"$.event.pipeline\"))\n",
    "        .withColumn(\n",
    "            \"instruments\",\n",
    "            regexp_replace(\n",
    "                get_json_object(col(\"json_str\"), \"$.event.instruments\"), r\"[\\\"\\[\\]]\", \"\"\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\"significant\", get_json_object(col(\"json_str\"), \"$.event.significant\"))\n",
    "        .withColumn(\"gracedb_url\", get_json_object(col(\"json_str\"), \"$.urls.gracedb\"))\n",
    "        .withColumn(\"prob_bns\", get_json_object(col(\"json_str\"), \"$.event.classification.BNS\"))\n",
    "        .withColumn(\"prob_bbh\", get_json_object(col(\"json_str\"), \"$.event.classification.BBH\"))\n",
    "        .withColumn(\"prob_nsbh\", get_json_object(col(\"json_str\"), \"$.event.classification.NSBH\"))\n",
    "        .withColumn(\n",
    "            \"prob_terrestrial\",\n",
    "            get_json_object(col(\"json_str\"), \"$.event.classification.Terrestrial\"),\n",
    "        )\n",
    "        .withColumn(\"prob_has_ns\", get_json_object(col(\"json_str\"), \"$.event.properties.HasNS\"))\n",
    "        .withColumn(\n",
    "            \"prob_has_remnant\", get_json_object(col(\"json_str\"), \"$.event.properties.HasRemnant\")\n",
    "        )\n",
    "        .withColumn(\"far\", get_json_object(col(\"json_str\"), \"$.event.far\"))\n",
    "        .select(\n",
    "            col(\"message_key\"),\n",
    "            col(\"json_str\").alias(\"gwalert_json\"),\n",
    "            col(\"topic\"),\n",
    "            col(\"superevent_id\"),\n",
    "            col(\"alert_type\"),\n",
    "            get_json_object(col(\"json_str\"), \"$.time_created\").alias(\"time_created\"),\n",
    "            col(\"gracedb_url\"),\n",
    "            col(\"significant\"),\n",
    "            col(\"group\"),\n",
    "            col(\"pipeline\"),\n",
    "            col(\"far\"),\n",
    "            col(\"instruments\"),\n",
    "            col(\"prob_bns\"),\n",
    "            col(\"prob_nsbh\"),\n",
    "            col(\"prob_bbh\"),\n",
    "            col(\"prob_terrestrial\"),\n",
    "            col(\"prob_has_ns\"),\n",
    "            col(\"prob_has_remnant\"),\n",
    "            # Document Text for RAG with null checks to avoid empty labels\n",
    "            concat_ws(\n",
    "                \" | \",\n",
    "                when(\n",
    "                    col(\"superevent_id\").isNotNull(),\n",
    "                    concat_ws(\": \", lit(\"ID\"), col(\"superevent_id\")),\n",
    "                ),\n",
    "                when(\n",
    "                    col(\"alert_type\").isNotNull(), concat_ws(\": \", lit(\"TYPE\"), col(\"alert_type\"))\n",
    "                ),\n",
    "                when(col(\"group\").isNotNull(), concat_ws(\": \", lit(\"GROUP\"), col(\"group\"))),\n",
    "                when(\n",
    "                    col(\"pipeline\").isNotNull(), concat_ws(\": \", lit(\"PIPELINE\"), col(\"pipeline\"))\n",
    "                ),\n",
    "                when(\n",
    "                    length(col(\"instruments\")) > 0,\n",
    "                    concat_ws(\": \", lit(\"INSTRUMENTS\"), col(\"instruments\")),\n",
    "                ),\n",
    "                when(\n",
    "                    col(\"significant\").isNotNull(),\n",
    "                    concat_ws(\": \", lit(\"SIGNIFICANT\"), col(\"significant\")),\n",
    "                ),\n",
    "                when(\n",
    "                    col(\"gracedb_url\").isNotNull(), concat_ws(\": \", lit(\"URL\"), col(\"gracedb_url\"))\n",
    "                ),\n",
    "            ).alias(\"document_text\"),\n",
    "            col(\"kafka_timestamp\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            col(\"partition\"),\n",
    "            col(\"offset\"),\n",
    "            current_timestamp().alias(\"silver_processed_timestamp\"),\n",
    "            current_date().alias(\"silver_processed_date\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"gcn_heartbeat\",\n",
    "    comment=\"GCN Heartbeat messages for monitoring - Silver layer\",\n",
    "    table_properties={\"quality\": \"silver\"},\n",
    ")\n",
    "def gcn_heartbeat():\n",
    "    return (\n",
    "        dlt.read_stream(\"gcn_raw\")\n",
    "        .filter(col(\"topic\") == \"gcn.heartbeat\")\n",
    "        .select(\n",
    "            col(\"message_key\"),\n",
    "            decode_utf8().alias(\"heartbeat_json\"),\n",
    "            col(\"topic\"),\n",
    "            col(\"kafka_timestamp\"),\n",
    "            col(\"ingestion_timestamp\"),\n",
    "            col(\"partition\"),\n",
    "            col(\"offset\"),\n",
    "            current_timestamp().alias(\"silver_processed_timestamp\"),\n",
    "            current_date().alias(\"silver_processed_date\"),\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•á Gold Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "    name=\"gcn_events_summarized\",\n",
    "    comment=\"Aggregated events linking narrative (Circulars) with facts (Notices) - Gold Layer\",\n",
    "    table_properties={\"quality\": \"gold\"},\n",
    ")\n",
    "def gcn_events_summarized():\n",
    "    # Leitura como Tabela (n√£o stream) para permitir agrega√ß√µes globais\n",
    "    circulars = dlt.read(\"gcn_circulars\")\n",
    "    gw_alerts = dlt.read(\"igwn_gwalert\")\n",
    "\n",
    "    # 1. Agregar Circulares por Event ID\n",
    "    # Cria narrativa consolidada para RAG\n",
    "    curr_circulars = (\n",
    "        circulars.groupBy(\"event_id\")\n",
    "        .agg(\n",
    "            count(\"circular_id\").alias(\"circular_count\"),\n",
    "            concat_ws(\"\\n\\n---\\n\\n\", collect_list(\"document_text\")).alias(\"scientific_narrative\"),\n",
    "            max(\"created_on\").alias(\"last_circular_date\"),\n",
    "        )\n",
    "        .filter(col(\"event_id\").isNotNull())\n",
    "    )\n",
    "\n",
    "    # 2. Preparar GW Alerts para Join (chave superevent_id)\n",
    "    curr_gw = (\n",
    "        gw_alerts.withColumnRenamed(\"superevent_id\", \"event_id\")\n",
    "        .select(\"event_id\", \"alert_type\", \"time_created\", \"document_text\")\n",
    "        .withColumnRenamed(\"document_text\", \"alert_context\")\n",
    "        .withColumnRenamed(\"time_created\", \"alert_time\")\n",
    "    )\n",
    "\n",
    "    # 3. Join Left (Baseado nas Circulares como fonte da verdade do evento nomeado)\n",
    "    return curr_circulars.join(curr_gw, \"event_id\", \"left\").select(\n",
    "        col(\"event_id\"),\n",
    "        col(\"circular_count\"),\n",
    "        col(\"last_circular_date\"),\n",
    "        coalesce(col(\"alert_time\"), col(\"last_circular_date\")).alias(\"event_time\"),\n",
    "        col(\"alert_type\"),\n",
    "        col(\"alert_context\"),\n",
    "        col(\"scientific_narrative\"),\n",
    "        current_timestamp().alias(\"gold_processed_timestamp\"),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "pipeline",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}